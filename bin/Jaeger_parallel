import subprocess
import os
import concurrent.futures
import time
from tqdm import tqdm
import argparse
import pandas as pd
from collections import defaultdict
from importlib.metadata import metadata, version


def dir_path(path):
    '''checks path and creates if absent'''
    if os.path.isdir(path):
        return path
    else:
        os.mkdir(path)
        return path


def file_path(path):
    '''checks if file is present'''
    if os.path.isfile(path):
        return path
    else:
        raise argparse.ArgumentTypeError(f"ERROR:{path} is not a valid file")
        
def cmdparser():
    '''cmdline argument parser'''
    parser = argparse.ArgumentParser(description=f'\n## Jaeger {version("jaeger")} (yet AnothEr phaGe idEntifier) Deep-learning based bacteriophage discovery (parallel execution) \nhttps://github.com/Yasas1994/Jaeger.git',
    usage=argparse.SUPPRESS,formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument("-i","--input",
                        type=file_path,
                        required=True,
                        help="path to a csv file containing input file paths")
    parser.add_argument("-o","--outpath", 
                        type=str,
                        required=True,
                        help='path to output directory')
    parser.add_argument("-of","--ofasta", 
                        type=str,
                        required=False,
                        help='path to output fasta file')
    parser.add_argument("--cutoff", 
                        type=float,
                        required=False,
                        default=2.9,
                        help='fasta output cutoff score')
    parser.add_argument("--fsize", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="length of the sliding window (value must be 2^n). default:2048")

    parser.add_argument("--stride", 
                        type=int,
                        nargs='?',
                        default=2048, 
                        help="stride of the sliding window. default:2048 (stride==fsize)")
    parser.add_argument("--batch", 
                        type=int,
                        nargs='?',
                        default=128, 
                        help="parallel batch size, set to a lower value if your gpu runs out of memory. default:128")
    parser.add_argument('--getalllogits',
                       action="store_true",
                        help="return position-wise logits for each prediction window as a .npy file" )
    parser.add_argument("--getalllabels", 
                        action="store_true",
                        help="get predicted labels for Non-Viral contigs. default:False")
    parser.add_argument("--meanscore",
                        action="store_true", 
                        help="output mean predictive score per contig. deafault:True")
    parser.add_argument("--fragscore", 
                        action="store_true", 
                        help="output percentage of perclass predictions per contig. deafault:True")
    misc = parser.add_argument_group('Misc. Options')

    misc.add_argument('-v', '--verbose', action="count", default=2,
                  help='Verbosity level : 1 warning, 2 info, 3 debug, (default info)')

    misc.add_argument('-f', '--overwrite', action="store_true", help='Overwrite existing files')   

    parser.add_argument("-mw","--maxworkers", 
                        type=int,
                        required=False,
                        default=4,
                        help='set the maxium number of workers for a single GPU')
    
    parser.add_argument("--ngpu",
                        type=int,
                        required=False,
                        default=2,
                        help='set the number of GPUs to use')
    return parser.parse_args()
    
class SubprocessPool:
    def __init__(self, max_workers_per_gpu, num_gpus,total_commands,commands):
        self.max_workers_per_gpu = max_workers_per_gpu
        self.num_gpus = num_gpus
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers_per_gpu*num_gpus)
        self.futures = {i:[] for i in range(num_gpus)}
        self.counter = {i:0 for i in range(num_gpus)}
        self.pending_commands = []
        self.pbar = tqdm(total=total_commands, position=0) 
        self.done = 0
        self.total = total_commands
        self.pending_commands=commands

    def submit(self, command):
        #check which gpu is vacant
        #print(self.counter)
        for key,value in self.counter.items():
            #print(key,value)
            if value < self.max_workers_per_gpu:
                #edit the command and specify the physicalid of the gpu to use
                command_ = command + f" --virtualgpu --physicalid {key}"
                future = self.executor.submit(self._run_subprocess, command_)
                self.futures[key].append(future)
                self.counter[key]+=1
                break
        #if value == self.max_workers_per_gpu and key == self.num_gpus:
            #if all workers are busy, append to pending commands
            

    def _run_subprocess(self, command):
        try:
            subprocess.run(command, shell=True, check=True, capture_output=True)
        except subprocess.CalledProcessError as e:
            print(f"Error executing '{command}': {e}")
        except Exception as e:
            print(f"An error occurred: {e}")

    def monitor_pool(self):
        while True:
            for key,values in self.futures.items():
                #print(key,values,self.pending_commands)
                for future in values:
                    if future.done():
                        self.futures[key].remove(future)
                        self.counter[key]-=1
                        self.pbar.update(1)
                        self.done += 1
            if self.counter[key] < self.max_workers_per_gpu and len(self.pending_commands) > 0:
                # Replenish the pool by submitting new tasks
                self.submit(self.pending_commands.pop(0))
                
            elif self.done == self.total:
                self.executor.shutdown() #shutdown the pool
                break #exit the loop
            time.sleep(1)  # Adjust sleep duration as needed
            

    def close(self):
        self.executor.shutdown()
    
if __name__ == '__main__':
    args = cmdparser()
    input_paths = pd.read_csv(args.input)
    
    NUMBER_OF_GPUS = args.ngpu
    MAX_WORKERS_PER_GPU = args.maxworkers
    
    NUMBER_OF_TASKS = len(input_paths['paths'])
    progress_bar = tqdm(total=NUMBER_OF_TASKS)
    
    
    template = ""
    if args.ofasta:
        template+= f' -of {args.ofasta}'
    if args.cutoff:
        template+= f' --cutoff {args.cutoff}'
    if args.fsize:
        template += f' --fsize {args.fsize}'
    if args.stride:
        template += f' --stride {args.stride}'
    if args.batch:
         template += f' --batch {args.batch}'
    if args.getalllogits:
         template += f' --getalllogits '
    if args.getalllabels:
         template += f' --getalllabels '
    if args.meanscore:
         template += f' --meanscore '
    if args.fragscore:
         template += f' --fragscore '
    # if args.verbose:
    #      template += f' --verbose {args.verbose} '  
    if args.overwrite:
         template += f' --overwrite '    
    
    
    ALL_COMMANDS = [f"Jaeger -i {i} -o {args.outpath} {template}" for i in input_paths['paths'].to_list()]
    pool = SubprocessPool(MAX_WORKERS_PER_GPU, NUMBER_OF_GPUS, NUMBER_OF_TASKS,ALL_COMMANDS)

    try:
        pool.monitor_pool()
    except KeyboardInterrupt:
        pool.close()
